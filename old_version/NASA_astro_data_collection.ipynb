{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f70a4361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying HEASARC TAP for fermigbrst table schema...\n",
      "Schema query complete.\n",
      "                 column_name datatype  \\\n",
      "0    flnc_band_phtflnc_error   double   \n",
      "1          flnc_sbpl_ergflux   double   \n",
      "2         flnc_plaw_phtfluxb   double   \n",
      "3          flnc_band_ergflux   double   \n",
      "4          flnc_sbpl_phtflux   double   \n",
      "..                       ...      ...   \n",
      "305                  fluence   double   \n",
      "306       pflx_comp_redchisq   double   \n",
      "307   back_interval_low_stop   double   \n",
      "308  flnc_sbpl_brken_neg_err   double   \n",
      "309  pflx_band_ergflnc_error   double   \n",
      "\n",
      "                                           description  \n",
      "0    Band Model Photon Fluence Error for Fluence Sp...  \n",
      "1                SBPL Energy Flux for Fluence Spectrum  \n",
      "2    Power Law Model 50-300 keV (BATSE) Photon Flux...  \n",
      "3          Band Model Energy Flux for Fluence Spectrum  \n",
      "4                SBPL Photon Flux for Fluence Spectrum  \n",
      "..                                                 ...  \n",
      "305                                10-1000 keV Fluence  \n",
      "306  Comptonized Model Reduced Chi-Squared for Peak...  \n",
      "307  Stop Time for Lower Background Selection Inter...  \n",
      "308  SBPL Break Energy Negative Error for Fluence S...  \n",
      "309  Band Model Energy Fluence Error for Peak Flux ...  \n",
      "\n",
      "[310 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from astroquery.heasarc import Heasarc\n",
    "\n",
    "heasarc = Heasarc()\n",
    "\n",
    "# ADQL query to get column names and metadata from fermigbrst table\n",
    "adql_schema_query = \"\"\"\n",
    "SELECT * \n",
    "FROM TAP_SCHEMA.columns \n",
    "WHERE table_name='fermigbrst'\n",
    "\"\"\"\n",
    "\n",
    "print(\"Querying HEASARC TAP for fermigbrst table schema...\")\n",
    "schema_table = heasarc.query_tap(adql_schema_query)\n",
    "print(\"Schema query complete.\")\n",
    "\n",
    "# Convert TAPResults to Astropy Table, then to pandas DataFrame for inspection\n",
    "schema_df = schema_table.to_table().to_pandas()\n",
    "print(schema_df[['column_name', 'datatype', 'description']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dec3fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df.to_csv('schema_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0377d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying HEASARC for Fermi GRB data in August 2017 with correct MJD range...\n",
      "Data query complete.\n",
      "Downloaded 251 events.\n",
      "\n",
      "--- Standardized HEASARC DataFrame ---\n",
      "      event_id                   utc_time  ra_deg  dec_deg  pos_error_deg  \\\n",
      "0  bn170116238 2017-01-16 05:43:15.259239   72.94   -87.43           9.37   \n",
      "1  bn170130697 2017-01-30 16:43:13.295769  296.39   -80.45          10.73   \n",
      "2  bn171206122 2017-12-06 02:55:44.936745    9.48   -78.20           6.03   \n",
      "3  bn170124874 2017-01-24 20:58:06.357821  282.04   -75.51           1.00   \n",
      "4  bn170121067 2017-01-21 01:36:53.640605    3.03   -75.62           4.07   \n",
      "\n",
      "   signal_strength   source event_type  \n",
      "0          6.49597  HEASARC        GRB  \n",
      "1          2.20144  HEASARC        GRB  \n",
      "2          6.62104  HEASARC        GRB  \n",
      "3          6.36266  HEASARC        GRB  \n",
      "4          6.79250  HEASARC        GRB  \n",
      "\n",
      "Data types of the final columns:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 251 entries, 0 to 250\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   event_id         251 non-null    object        \n",
      " 1   utc_time         251 non-null    datetime64[ns]\n",
      " 2   ra_deg           251 non-null    float64       \n",
      " 3   dec_deg          251 non-null    float64       \n",
      " 4   pos_error_deg    251 non-null    float64       \n",
      " 5   signal_strength  251 non-null    float64       \n",
      " 6   source           251 non-null    object        \n",
      " 7   event_type       251 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(4), object(3)\n",
      "memory usage: 15.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from astroquery.heasarc import Heasarc\n",
    "from astropy.time import Time\n",
    "import pandas as pd\n",
    "\n",
    "heasarc = Heasarc()\n",
    "\n",
    "start_date = '2017-07-01'\n",
    "end_date = '2017-09-30'\n",
    "\n",
    "# convert to MJD numbers\n",
    "start_mjd = Time(start_date).mjd\n",
    "end_mjd = Time(end_date).mjd\n",
    "\n",
    "adql_data_query = f\"\"\"\n",
    "SELECT trigger_name, trigger_time, ra, dec, error_radius, flux_256\n",
    "FROM fermigbrst\n",
    "WHERE trigger_time BETWEEN {start_mjd} AND {end_mjd}\n",
    "\"\"\"\n",
    "\n",
    "print(\"Querying HEASARC for Fermi GRB data in August 2017 with correct MJD range...\")\n",
    "grb_table = heasarc.query_tap(adql_data_query)\n",
    "print(\"Data query complete.\")\n",
    "\n",
    "raw_heasarc_df = grb_table.to_table().to_pandas()\n",
    "print(f\"Downloaded {len(raw_heasarc_df)} events.\")\n",
    "\n",
    "column_mapping = {\n",
    "    'trigger_name': 'event_id',\n",
    "    'trigger_time': 'utc_time',\n",
    "    'ra': 'ra_deg',\n",
    "    'dec': 'dec_deg',\n",
    "    'error_radius': 'pos_error_deg',\n",
    "    'flux_256': 'signal_strength'\n",
    "}\n",
    "\n",
    "heasarc_df = raw_heasarc_df.rename(columns=column_mapping)\n",
    "\n",
    "# Convert MJD numeric trigger_time to datetime using astropy\n",
    "heasarc_df['utc_time'] = Time(heasarc_df['utc_time'], format='mjd').to_datetime()\n",
    "\n",
    "# Convert other numeric columns\n",
    "for col in ['ra_deg', 'dec_deg', 'pos_error_deg', 'signal_strength']:\n",
    "    heasarc_df[col] = pd.to_numeric(heasarc_df[col], errors='coerce')\n",
    "\n",
    "heasarc_df.dropna(inplace=True)\n",
    "\n",
    "# Add metadata columns\n",
    "heasarc_df['source'] = 'HEASARC'\n",
    "heasarc_df['event_type'] = 'GRB'\n",
    "\n",
    "print(\"\\n--- Standardized HEASARC DataFrame ---\")\n",
    "print(heasarc_df.head())\n",
    "print(\"\\nData types of the final columns:\")\n",
    "print(heasarc_df.info())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e641827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "heasarc_df.to_csv('heasarc_df_year_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "062fd264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded heasarc_df.csv\n",
      "Loaded and prepared 28 events for analysis.\n",
      "\n",
      "--- Starting Adaptive Candidate Search ---\n",
      "Search complete. Found 0 candidate pairs.\n",
      "\n",
      "No correlated event candidates found within the specified parameters.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery.simbad import Simbad\n",
    "import astropy.units as u\n",
    "\n",
    "# --- STEP 1: LOAD AND PREPARE THE DATASET ---\n",
    "\n",
    "# Load the CSV file you provided\n",
    "try:\n",
    "    master_df = pd.read_csv('heasarc_df.csv')\n",
    "    print(\"Successfully loaded heasarc_df.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: heasarc_df.csv not found. Please ensure the file is in the correct directory.\")\n",
    "    exit()\n",
    "\n",
    "# Ensure the utc_time column is in datetime format\n",
    "master_df['utc_time'] = pd.to_datetime(master_df['utc_time'])\n",
    "\n",
    "# Sort the master list by time, which is crucial for the search algorithm\n",
    "master_df.sort_values(by='utc_time', inplace=True)\n",
    "master_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Feature Engineering: Calculate percentile rank for signal_strength\n",
    "# Since we only have one event type (GRB), this is straightforward\n",
    "master_df['signal_percentile'] = master_df['signal_strength'].rank(pct=True)\n",
    "\n",
    "print(f\"Loaded and prepared {len(master_df)} events for analysis.\")\n",
    "\n",
    "\n",
    "# --- STEP 2: DEFINE THE CORE ENGINE LOGIC ---\n",
    "\n",
    "# [cite_start]Configuration Engine [cite: 1]\n",
    "EVENT_CONFIG = {\n",
    "    'GRB': {'time_window_days': 0.5, 'max_search_radius_deg': 5.0},\n",
    "    'DEFAULT': {'time_window_days': 1.0, 'max_search_radius_deg': 10.0}\n",
    "}\n",
    "\n",
    "# Scoring Weights\n",
    "WEIGHTS = {'W_st': 0.5, 'W_sig': 0.3, 'W_ctx': 0.2}\n",
    "\n",
    "# Helper function to calculate angular distance\n",
    "def calculate_angular_distance(ra1, dec1, ra2, dec2):\n",
    "    c1 = SkyCoord(ra=ra1*u.degree, dec=dec1*u.degree, frame='icrs')\n",
    "    c2 = SkyCoord(ra=ra2*u.degree, dec=dec2*u.degree, frame='icrs')\n",
    "    return c1.separation(c2).degree\n",
    "\n",
    "# The main scoring function\n",
    "def calculate_scores(event_A, event_B):\n",
    "    features = {}\n",
    "    \n",
    "    # [cite_start]Feature Engineering based on your proposal's Phase 3 [cite: 1]\n",
    "    features['time_delta_sec'] = abs((event_A['utc_time'] - event_B['utc_time']).total_seconds())\n",
    "    features['angular_dist_deg'] = calculate_angular_distance(event_A['ra_deg'], event_A['dec_deg'], event_B['ra_deg'], event_B['dec_deg'])\n",
    "    \n",
    "    # [cite_start]This is your 'significance_of_match' feature [cite: 1]\n",
    "    # Adding a small epsilon to avoid division by zero\n",
    "    features['S_match'] = features['angular_dist_deg'] / (event_A['pos_error_deg'] + event_B['pos_error_deg'] + 1e-6)\n",
    "    \n",
    "    # --- Calculate Sub-scores ---\n",
    "    # 1. Spatio-Temporal Score\n",
    "    score_spatial = np.exp(-features['S_match'])\n",
    "    score_temporal = np.exp(-features['time_delta_sec'] / 3600) # Characteristic timescale of 1 hour\n",
    "    features['score_spatiotemporal'] = score_spatial * score_temporal\n",
    "\n",
    "    # 2. Significance Score\n",
    "    norm_sig_A = event_A['signal_percentile']\n",
    "    norm_sig_B = event_B['signal_percentile']\n",
    "    features['score_significance'] = norm_sig_A * norm_sig_B\n",
    "\n",
    "    # 3. Contextual Score\n",
    "    try:\n",
    "        # Check for a known galaxy near the event's location\n",
    "        result_table = Simbad.query_region(SkyCoord(ra=event_A['ra_deg']*u.degree, dec=event_A['dec_deg']*u.degree), radius=0.5*u.degree)\n",
    "        is_galaxy_nearby = any('G' in t for t in result_table['OTYPE']) if result_table else False\n",
    "        features['score_contextual'] = 1.0 if is_galaxy_nearby else 0.1\n",
    "    except Exception:\n",
    "        features['score_contextual'] = 0.1 # Default to low score on error if query fails\n",
    "\n",
    "    # --- Final Confidence Score ---\n",
    "    features['confidence_score'] = (WEIGHTS['W_st'] * features['score_spatiotemporal'] +\n",
    "                                    WEIGHTS['W_sig'] * features['score_significance'] +\n",
    "                                    WEIGHTS['W_ctx'] * features['score_contextual'])\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "# --- STEP 3: RUN THE ADAPTIVE SEARCH AND SCORE CANDIDATES ---\n",
    "\n",
    "scored_candidates = []\n",
    "print(\"\\n--- Starting Adaptive Candidate Search ---\")\n",
    "\n",
    "for i in range(len(master_df)):\n",
    "    event_A = master_df.iloc[i]\n",
    "    config = EVENT_CONFIG.get(event_A['event_type'], EVENT_CONFIG['DEFAULT'])\n",
    "    \n",
    "    # Inner loop for subsequent events (time-windowed search)\n",
    "    for j in range(i + 1, len(master_df)):\n",
    "        event_B = master_df.iloc[j]\n",
    "        \n",
    "        # Time Check: If the next event is outside the time window, break the inner loop\n",
    "        time_delta = event_B['utc_time'] - event_A['utc_time']\n",
    "        if time_delta.days > config['time_window_days']:\n",
    "            break\n",
    "            \n",
    "        # Spatial Check\n",
    "        angular_dist = calculate_angular_distance(event_A['ra_deg'], event_A['dec_deg'], event_B['ra_deg'], event_B['dec_deg'])\n",
    "        if angular_dist < config['max_search_radius_deg']:\n",
    "            # This is a candidate pair, now score it\n",
    "            scores = calculate_scores(event_A, event_B)\n",
    "            \n",
    "            result = {\n",
    "                'event_A_id': event_A['event_id'],\n",
    "                'event_B_id': event_B['event_id'],\n",
    "                'time_delta_sec': scores['time_delta_sec'],\n",
    "                'angular_dist_deg': scores['angular_dist_deg'],\n",
    "                'confidence_score': scores['confidence_score'],\n",
    "                'score_spatiotemporal': scores['score_spatiotemporal'],\n",
    "                'score_significance': scores['score_significance'],\n",
    "                'score_contextual': scores['score_contextual']\n",
    "            }\n",
    "            scored_candidates.append(result)\n",
    "\n",
    "print(f\"Search complete. Found {len(scored_candidates)} candidate pairs.\")\n",
    "\n",
    "# --- STEP 4: FINAL RANKING AND OUTPUT ---\n",
    "\n",
    "if scored_candidates:\n",
    "    # Convert the list of results into a final DataFrame\n",
    "    final_results_df = pd.DataFrame(scored_candidates)\n",
    "\n",
    "    # Sort by the confidence score to find the best candidates\n",
    "    final_results_df.sort_values(by='confidence_score', ascending=False, inplace=True)\n",
    "    final_results_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(\"\\n--- Top 10 Correlated Event Candidates ---\")\n",
    "    print(final_results_df.head(10).to_string())\n",
    "else:\n",
    "    print(\"\\nNo correlated event candidates found within the specified parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afce2af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 251 events from heasarc_df_year_2017.csv\n",
      "Successfully loaded 47 events from gw_events_complete3.csv\n",
      "\n",
      "Combined and prepared a total of 298 events for analysis.\n",
      "\n",
      "--- Starting Adaptive Candidate Search ---\n",
      "Search complete. Found 13 candidate pairs.\n",
      "\n",
      "--- Top 10 Correlated Event Candidates ---\n",
      "        event_A_id event_A_type       event_B_id event_B_type confidence_score score_spatiotemporal score_significance score_contextual time_delta_sec angular_dist_deg\n",
      "0      bn170817529          GRB         GW170817           GW            0.572                0.990              0.191              0.1           34.9            0.001\n",
      "1         GW190412           GW  GW190413_052954           GW            0.126                0.000              0.353              0.1       86,350.4           20.928\n",
      "2  GW190706_222641           GW  GW190707_093326           GW            0.068                0.000              0.159              0.1       40,004.8           37.954\n",
      "3  GW190803_022701           GW  GW190805_211137           GW            0.068                0.000              0.159              0.1      240,275.4           37.932\n",
      "4  GW190517_055101           GW  GW190519_153544           GW            0.067                0.000              0.156              0.1      207,882.6           49.552\n",
      "5  GW190706_222641           GW  GW190708_232457           GW            0.059                0.000              0.131              0.1      176,296.0           35.928\n",
      "6      bn170804911          GRB      bn170805901          GRB            0.049                0.000              0.096              0.1       85,528.1           14.275\n",
      "7  GW191103_012549           GW  GW191105_143521           GW            0.046                0.000              0.087              0.1      220,172.4           30.145\n",
      "8  GW190929_012149           GW  GW190930_133541           GW            0.045                0.000              0.083              0.1      130,431.7           49.628\n",
      "9         GW190425           GW  GW190426_152155           GW            0.035                0.000              0.051              0.1      111,830.3           33.116\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery.simbad import Simbad\n",
    "import astropy.units as u\n",
    "\n",
    "# --- STEP 1: LOAD AND COMBINE YOUR DATASETS ---\n",
    "\n",
    "# --- STEP 1: LOAD AND COMBINE YOUR DATASETS (Corrected for Timezone) ---\n",
    "\n",
    "try:\n",
    "    # Load the HEASARC GRB data\n",
    "    heasarc_df = pd.read_csv('heasarc_df_year_2017.csv')\n",
    "    print(f\"Successfully loaded {len(heasarc_df)} events from heasarc_df_year_2017.csv\")\n",
    "    \n",
    "    # Load the GWOSC GW data\n",
    "    gw_df = pd.read_csv('gw_events_complete3.csv')\n",
    "    print(f\"Successfully loaded {len(gw_df)} events from gw_events_complete3.csv\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not find a data file. Make sure both CSV files are in the correct directory.\")\n",
    "    print(e)\n",
    "    exit()\n",
    "\n",
    "# Standardize the utc_time column to datetime objects\n",
    "heasarc_df['utc_time'] = pd.to_datetime(heasarc_df['utc_time'])\n",
    "gw_df['utc_time'] = pd.to_datetime(gw_df['utc_time'])\n",
    "\n",
    "# --- FIX: Ensure both columns are timezone-aware and set to UTC ---\n",
    "heasarc_df['utc_time'] = heasarc_df['utc_time'].dt.tz_localize(None).dt.tz_localize('UTC')\n",
    "gw_df['utc_time'] = gw_df['utc_time'].dt.tz_localize(None).dt.tz_localize('UTC')\n",
    "\n",
    "# Combine into a single master DataFrame\n",
    "master_df = pd.concat([heasarc_df, gw_df], ignore_index=True)\n",
    "\n",
    "# Sort the master list by time, which is crucial for the search algorithm\n",
    "master_df.sort_values(by='utc_time', inplace=True)\n",
    "master_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Feature Engineering: Calculate percentile rank for signal_strength within each event type\n",
    "master_df['signal_percentile'] = master_df.groupby('event_type')['signal_strength'].rank(pct=True)\n",
    "\n",
    "print(f\"\\nCombined and prepared a total of {len(master_df)} events for analysis.\")\n",
    "\n",
    "\n",
    "# --- STEP 2: DEFINE THE CORE ENGINE LOGIC ---\n",
    "\n",
    "# Configuration Engine for the adaptive search\n",
    "EVENT_CONFIG = {\n",
    "    'GW': {'time_window_days': 2.0},\n",
    "    'GRB': {'time_window_days': 0.5},\n",
    "    'DEFAULT': {'time_window_days': 1.0}\n",
    "}\n",
    "\n",
    "# Scoring Weights for the final confidence score\n",
    "WEIGHTS = {'W_st': 0.5, 'W_sig': 0.3, 'W_ctx': 0.2}\n",
    "\n",
    "# Helper function to calculate angular distance between two points on the sky\n",
    "def calculate_angular_distance(ra1, dec1, ra2, dec2):\n",
    "    c1 = SkyCoord(ra=ra1*u.degree, dec=dec1*u.degree, frame='icrs')\n",
    "    c2 = SkyCoord(ra=ra2*u.degree, dec=dec2*u.degree, frame='icrs')\n",
    "    return c1.separation(c2).degree\n",
    "\n",
    "# The main scoring function that calculates all features and scores for a pair\n",
    "def calculate_scores(event_A, event_B):\n",
    "    features = {}\n",
    "    \n",
    "    # Feature Engineering\n",
    "    features['time_delta_sec'] = abs((event_A['utc_time'] - event_B['utc_time']).total_seconds())\n",
    "    features['angular_dist_deg'] = calculate_angular_distance(event_A['ra_deg'], event_A['dec_deg'], event_B['ra_deg'], event_B['dec_deg'])\n",
    "    features['S_match'] = features['angular_dist_deg'] / (event_A['pos_error_deg'] + event_B['pos_error_deg'] + 1e-6)\n",
    "    \n",
    "    # --- Calculate Sub-scores ---\n",
    "    # 1. Spatio-Temporal Score\n",
    "    score_spatial = np.exp(-features['S_match'])\n",
    "    score_temporal = np.exp(-features['time_delta_sec'] / 3600) # Characteristic timescale of 1 hour\n",
    "    features['score_spatiotemporal'] = score_spatial * score_temporal\n",
    "\n",
    "    # 2. Significance Score\n",
    "    norm_sig_A = event_A['signal_percentile']\n",
    "    norm_sig_B = event_B['signal_percentile']\n",
    "    features['score_significance'] = norm_sig_A * norm_sig_B\n",
    "\n",
    "    # 3. Contextual Score (with error handling)\n",
    "    try:\n",
    "        result_table = Simbad.query_region(SkyCoord(ra=event_A['ra_deg']*u.degree, dec=event_A['dec_deg']*u.degree), radius=0.5*u.degree)\n",
    "        is_galaxy_nearby = any('G' in t for t in result_table['OTYPE']) if result_table else False\n",
    "        features['score_contextual'] = 1.0 if is_galaxy_nearby else 0.1\n",
    "    except Exception:\n",
    "        features['score_contextual'] = 0.1 # Default to low score on query error\n",
    "\n",
    "    # --- Final Confidence Score ---\n",
    "    features['confidence_score'] = (WEIGHTS['W_st'] * features['score_spatiotemporal'] +\n",
    "                                    WEIGHTS['W_sig'] * features['score_significance'] +\n",
    "                                    WEIGHTS['W_ctx'] * features['score_contextual'])\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "# --- STEP 3: RUN THE ADAPTIVE SEARCH AND SCORE CANDIDATES ---\n",
    "\n",
    "scored_candidates = []\n",
    "print(\"\\n--- Starting Adaptive Candidate Search ---\")\n",
    "\n",
    "for i in range(len(master_df)):\n",
    "    event_A = master_df.iloc[i]\n",
    "    config = EVENT_CONFIG.get(event_A['event_type'], EVENT_CONFIG['DEFAULT'])\n",
    "    \n",
    "    for j in range(i + 1, len(master_df)):\n",
    "        event_B = master_df.iloc[j]\n",
    "        \n",
    "        # Time Check: Break inner loop if outside the adaptive time window\n",
    "        time_delta = event_B['utc_time'] - event_A['utc_time']\n",
    "        if time_delta.days > config['time_window_days']:\n",
    "            break\n",
    "            \n",
    "        # Spatial Check: Only consider events where the angular distance is less than the SUM of their error radii\n",
    "        # This is a more intelligent check than a fixed radius.\n",
    "        if calculate_angular_distance(event_A['ra_deg'], event_A['dec_deg'], event_B['ra_deg'], event_B['dec_deg']) < (event_A['pos_error_deg'] + event_B['pos_error_deg']):\n",
    "            scores = calculate_scores(event_A, event_B)\n",
    "            \n",
    "            result = {\n",
    "                'event_A_id': event_A['event_id'],\n",
    "                'event_A_type': event_A['event_type'],\n",
    "                'event_B_id': event_B['event_id'],\n",
    "                'event_B_type': event_B['event_type'],\n",
    "                'confidence_score': scores['confidence_score'],\n",
    "                'score_spatiotemporal': scores['score_spatiotemporal'],\n",
    "                'score_significance': scores['score_significance'],\n",
    "                'score_contextual': scores['score_contextual'],\n",
    "                'time_delta_sec': scores['time_delta_sec'],\n",
    "                'angular_dist_deg': scores['angular_dist_deg'],\n",
    "            }\n",
    "            scored_candidates.append(result)\n",
    "\n",
    "print(f\"Search complete. Found {len(scored_candidates)} candidate pairs.\")\n",
    "\n",
    "# --- STEP 4: FINAL RANKING AND OUTPUT ---\n",
    "\n",
    "if scored_candidates:\n",
    "    final_results_df = pd.DataFrame(scored_candidates)\n",
    "    final_results_df.sort_values(by='confidence_score', ascending=False, inplace=True)\n",
    "    final_results_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(\"\\n--- Top 10 Correlated Event Candidates ---\")\n",
    "    # Displaying with formatted columns for better readability\n",
    "    print(final_results_df.head(10).to_string(formatters={\n",
    "        'confidence_score': '{:,.3f}'.format,\n",
    "        'score_spatiotemporal': '{:,.3f}'.format,\n",
    "        'score_significance': '{:,.3f}'.format,\n",
    "        'score_contextual': '{:,.1f}'.format,\n",
    "        'time_delta_sec': '{:,.1f}'.format,\n",
    "        'angular_dist_deg': '{:,.3f}'.format\n",
    "    }))\n",
    "else:\n",
    "    print(\"\\nNo correlated event candidates found within the specified parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad95305",
   "metadata": {},
   "source": [
    "correct script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93999b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 251 events from heasarc_df_year_2017.csv\n",
      "Successfully loaded 47 events from gw_events_complete3.csv\n",
      "\n",
      "Combined and prepared a total of 298 events for analysis.\n",
      "\n",
      "--- Starting Adaptive Candidate Search with Corrected Logic ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 109\u001b[39m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m calculate_angular_distance(event_A[\u001b[33m'\u001b[39m\u001b[33mra_deg\u001b[39m\u001b[33m'\u001b[39m], event_A[\u001b[33m'\u001b[39m\u001b[33mdec_deg\u001b[39m\u001b[33m'\u001b[39m], event_B[\u001b[33m'\u001b[39m\u001b[33mra_deg\u001b[39m\u001b[33m'\u001b[39m], event_B[\u001b[33m'\u001b[39m\u001b[33mdec_deg\u001b[39m\u001b[33m'\u001b[39m]) < (event_A[\u001b[33m'\u001b[39m\u001b[33mpos_error_deg\u001b[39m\u001b[33m'\u001b[39m] + event_B[\u001b[33m'\u001b[39m\u001b[33mpos_error_deg\u001b[39m\u001b[33m'\u001b[39m]):\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     scores = \u001b[43mcalculate_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_B\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m     result = {\n\u001b[32m    112\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mevent_A_id\u001b[39m\u001b[33m'\u001b[39m: event_A[\u001b[33m'\u001b[39m\u001b[33mevent_id\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mevent_A_type\u001b[39m\u001b[33m'\u001b[39m: event_A[\u001b[33m'\u001b[39m\u001b[33mevent_type\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    113\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mevent_B_id\u001b[39m\u001b[33m'\u001b[39m: event_B[\u001b[33m'\u001b[39m\u001b[33mevent_id\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mevent_B_type\u001b[39m\u001b[33m'\u001b[39m: event_B[\u001b[33m'\u001b[39m\u001b[33mevent_type\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    116\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtime_delta_sec\u001b[39m\u001b[33m'\u001b[39m: scores[\u001b[33m'\u001b[39m\u001b[33mtime_delta_sec\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mangular_dist_deg\u001b[39m\u001b[33m'\u001b[39m: scores[\u001b[33m'\u001b[39m\u001b[33mangular_dist_deg\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    117\u001b[39m     }\n\u001b[32m    118\u001b[39m     scored_candidates.append(result)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mcalculate_scores\u001b[39m\u001b[34m(event_A, event_B)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;66;03m# Query a slightly larger region to ensure we find the host\u001b[39;00m\n\u001b[32m     74\u001b[39m     search_radius = \u001b[38;5;28mmax\u001b[39m(\u001b[32m0.5\u001b[39m, event_A[\u001b[33m'\u001b[39m\u001b[33mpos_error_deg\u001b[39m\u001b[33m'\u001b[39m]) * u.degree\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     result_table = \u001b[43mSimbad\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery_region\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSkyCoord\u001b[49m\u001b[43m(\u001b[49m\u001b[43mra\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevent_A\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mra_deg\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m*\u001b[49m\u001b[43mu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevent_A\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdec_deg\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m*\u001b[49m\u001b[43mu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdegree\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m=\u001b[49m\u001b[43msearch_radius\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     \u001b[38;5;66;03m# Check for various galaxy classifications, not just 'G'\u001b[39;00m\n\u001b[32m     78\u001b[39m     galaxy_types = [\u001b[33m'\u001b[39m\u001b[33mG\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mGalaxy\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mLINER\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mSeyfert\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mPartofG\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Research\\Try_out\\.venv\\Lib\\site-packages\\astropy\\utils\\decorators.py:620\u001b[39m, in \u001b[36mdeprecated_renamed_argument.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    617\u001b[39m             msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m        Use \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malternative\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    618\u001b[39m         warnings.warn(msg, warning_type, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Research\\Try_out\\.venv\\Lib\\site-packages\\astroquery\\simbad\\core.py:784\u001b[39m, in \u001b[36mSimbadClass.query_region\u001b[39m\u001b[34m(self, coordinates, radius, criteria, get_query_payload, equinox, epoch, cache)\u001b[39m\n\u001b[32m    780\u001b[39m     radius = coord.Angle(radius)\n\u001b[32m    781\u001b[39m     instance_criteria.append(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCONTAINS(POINT(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mICRS\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, basic.ra, basic.dec), \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    782\u001b[39m                              \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCIRCLE(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mICRS\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcenter.ra.deg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcenter.dec.deg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    783\u001b[39m                              \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mradius.to(u.deg).value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)) = 1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mget_query_payload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_query_payload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[38;5;66;03m# from uploadLimit in SIMBAD's capabilities\u001b[39;00m\n\u001b[32m    788\u001b[39m \u001b[38;5;66;03m# http://simbad.cds.unistra.fr/simbad/sim-tap/capabilities\u001b[39;00m\n\u001b[32m    789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(center) > \u001b[38;5;28mself\u001b[39m.uploadlimit:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Research\\Try_out\\.venv\\Lib\\site-packages\\astroquery\\simbad\\core.py:1551\u001b[39m, in \u001b[36mSimbadClass._query\u001b[39m\u001b[34m(self, top, columns, joins, criteria, from_table, distinct, get_query_payload, **uploads)\u001b[39m\n\u001b[32m   1547\u001b[39m     criteria = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1549\u001b[39m query = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSELECT\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdistinct_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtop_part\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcolumns\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m FROM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfrom_table\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mjoin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcriteria\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1551\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquery_tap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_query_payload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_query_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mmaxrec\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhardlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[43m                          \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43muploads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1555\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m top != \u001b[32m0\u001b[39m:\n\u001b[32m   1556\u001b[39m     warnings.warn(\u001b[33m\"\u001b[39m\u001b[33mThe request executed correctly, but there was no data corresponding\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1557\u001b[39m                   \u001b[33m\"\u001b[39m\u001b[33m to these criteria in SIMBAD\u001b[39m\u001b[33m\"\u001b[39m, NoResultsWarning)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Research\\Try_out\\.venv\\Lib\\site-packages\\astroquery\\simbad\\core.py:1464\u001b[39m, in \u001b[36mSimbadClass.query_tap\u001b[39m\u001b[34m(self, query, maxrec, get_query_payload, **uploads)\u001b[39m\n\u001b[32m   1462\u001b[39m \u001b[38;5;66;03m# without uploads we call the version with cache\u001b[39;00m\n\u001b[32m   1463\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m uploads == {}:\n\u001b[32m-> \u001b[39m\u001b[32m1464\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_cached_query_tap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxrec\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxrec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1465\u001b[39m \u001b[38;5;66;03m# with uploads it has to be without cache\u001b[39;00m\n\u001b[32m   1466\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tap.run_async(query, maxrec=maxrec, uploads=uploads).to_table()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Research\\Try_out\\.venv\\Lib\\site-packages\\astroquery\\simbad\\core.py:75\u001b[39m, in \u001b[36m_cached_query_tap\u001b[39m\u001b[34m(tap, query, maxrec)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;129m@lru_cache\u001b[39m(\u001b[32m256\u001b[39m)\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_cached_query_tap\u001b[39m(tap, query: \u001b[38;5;28mstr\u001b[39m, *, maxrec=\u001b[32m10000\u001b[39m):\n\u001b[32m     53\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Cache version of query TAP.\u001b[39;00m\n\u001b[32m     54\u001b[39m \n\u001b[32m     55\u001b[39m \u001b[33;03m    This private function is called when query_tap is executed without an\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     73\u001b[39m \u001b[33;03m        The response returned by SIMBAD.\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtap\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxrec\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxrec\u001b[49m\u001b[43m)\u001b[49m.to_table()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Research\\Try_out\\.venv\\Lib\\site-packages\\pyvo\\dal\\tap.py:282\u001b[39m, in \u001b[36mTAPService.run_sync\u001b[39m\u001b[34m(self, query, language, maxrec, uploads, **keywords)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_sync\u001b[39m(\n\u001b[32m    254\u001b[39m         \u001b[38;5;28mself\u001b[39m, query, *, language=\u001b[33m\"\u001b[39m\u001b[33mADQL\u001b[39m\u001b[33m\"\u001b[39m, maxrec=\u001b[38;5;28;01mNone\u001b[39;00m, uploads=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    255\u001b[39m         **keywords):\n\u001b[32m    256\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    257\u001b[39m \u001b[33;03m    runs sync query and returns its result\u001b[39;00m\n\u001b[32m    258\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    278\u001b[39m \u001b[33;03m    TAPResults\u001b[39;00m\n\u001b[32m    279\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxrec\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxrec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muploads\u001b[49m\u001b[43m=\u001b[49m\u001b[43muploads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Research\\Try_out\\.venv\\Lib\\site-packages\\pyvo\\dal\\tap.py:1150\u001b[39m, in \u001b[36mTAPQuery.execute\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1137\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1138\u001b[39m \u001b[33;03m    submit the query and return the results as a TAPResults instance\u001b[39;00m\n\u001b[32m   1139\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1148\u001b[39m \u001b[33;03m       for errors parsing the VOTable response\u001b[39;00m\n\u001b[32m   1149\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m TAPResults(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute_votable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, url=\u001b[38;5;28mself\u001b[39m.queryurl, session=\u001b[38;5;28mself\u001b[39m._session)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Research\\Try_out\\.venv\\Lib\\site-packages\\pyvo\\dal\\query.py:260\u001b[39m, in \u001b[36mDALQuery.execute_votable\u001b[39m\u001b[34m(self, post)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    236\u001b[39m \u001b[33;03mSubmit the query and return the results as an AstroPy votable instance.\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[33;03mAs this is the level where qualified error messages are available,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m \u001b[33;03mDALQueryError\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m votableparse(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m)\u001b[49m.read)\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    262\u001b[39m     \u001b[38;5;28mself\u001b[39m.raise_if_error()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Research\\Try_out\\.venv\\Lib\\site-packages\\pyvo\\dal\\tap.py:1134\u001b[39m, in \u001b[36mTAPQuery.execute_stream\u001b[39m\u001b[34m(self, post)\u001b[39m\n\u001b[32m   1130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mode != \u001b[33m\"\u001b[39m\u001b[33msync\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1131\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DALServiceError(\n\u001b[32m   1132\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot execute a non-synchronous query. Use submit instead\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1134\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Research\\Try_out\\.venv\\Lib\\site-packages\\pyvo\\utils\\decorators.py:9\u001b[39m, in \u001b[36mstream_decode_content.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     raw = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     raw.read = partial(raw.read, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m raw\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Research\\Try_out\\.venv\\Lib\\site-packages\\pyvo\\dal\\query.py:209\u001b[39m, in \u001b[36mDALQuery.execute_stream\u001b[39m\u001b[34m(self, post)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;129m@stream_decode_content\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_stream\u001b[39m(\u001b[38;5;28mself\u001b[39m, *, post=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    203\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    204\u001b[39m \u001b[33;03m    Submit the query and return the raw response as a file stream.\u001b[39;00m\n\u001b[32m    205\u001b[39m \n\u001b[32m    206\u001b[39m \u001b[33;03m    No exceptions are raised here because non-2xx responses might still\u001b[39;00m\n\u001b[32m    207\u001b[39m \u001b[33;03m    contain payload. They can be raised later by calling ``raise_if_error``\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    212\u001b[39m         response.raise_for_status()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Research\\Try_out\\.venv\\Lib\\site-packages\\pyvo\\dal\\tap.py:1167\u001b[39m, in \u001b[36mTAPQuery.submit\u001b[39m\u001b[34m(self, post)\u001b[39m\n\u001b[32m   1159\u001b[39m url = \u001b[38;5;28mself\u001b[39m.queryurl\n\u001b[32m   1161\u001b[39m files = {\n\u001b[32m   1162\u001b[39m     upload.name: upload.fileobj()\n\u001b[32m   1163\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m upload \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._uploads\n\u001b[32m   1164\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m upload.is_inline\n\u001b[32m   1165\u001b[39m }\n\u001b[32m-> \u001b[39m\u001b[32m1167\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_session\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[38;5;66;03m# requests doesn't decode the content by default\u001b[39;00m\n\u001b[32m   1170\u001b[39m response.raw.read = partial(response.raw.read, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Research\\Try_out\\.venv\\Lib\\site-packages\\requests\\sessions.py:637\u001b[39m, in \u001b[36mSession.post\u001b[39m\u001b[34m(self, url, data, json, **kwargs)\u001b[39m\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    627\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    628\u001b[39m \n\u001b[32m    629\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    634\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    635\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Research\\Try_out\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Research\\Try_out\\.venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Research\\Try_out\\.venv\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Research\\Try_out\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Research\\Try_out\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Research\\Try_out\\.venv\\Lib\\site-packages\\urllib3\\connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\http\\client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\ssl.py:1251\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1249\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1250\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\ssl.py:1103\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery.simbad import Simbad\n",
    "import astropy.units as u\n",
    "\n",
    "# --- STEP 1: LOAD AND COMBINE YOUR DATASETS (WITH TIMEZONE FIX) ---\n",
    "\n",
    "try:\n",
    "    heasarc_df = pd.read_csv('heasarc_df_year_2017.csv')\n",
    "    print(f\"Successfully loaded {len(heasarc_df)} events from heasarc_df_year_2017.csv\")\n",
    "    gw_df = pd.read_csv('gw_events_complete3.csv')\n",
    "    print(f\"Successfully loaded {len(gw_df)} events from gw_events_complete3.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not find a data file. Make sure both CSV files are in the correct directory.\")\n",
    "    print(e)\n",
    "    exit()\n",
    "\n",
    "# Convert to datetime objects first\n",
    "heasarc_df['utc_time'] = pd.to_datetime(heasarc_df['utc_time'])\n",
    "gw_df['utc_time'] = pd.to_datetime(gw_df['utc_time'])\n",
    "\n",
    "# ### FIX 1: TIMEZONE CORRECTION ###\n",
    "# Standardize both DataFrames to the UTC timezone to ensure correct time difference calculations.\n",
    "heasarc_df['utc_time'] = heasarc_df['utc_time'].dt.tz_localize('UTC')\n",
    "gw_df['utc_time'] = gw_df['utc_time'].dt.tz_localize('UTC')\n",
    "\n",
    "master_df = pd.concat([heasarc_df, gw_df], ignore_index=True)\n",
    "master_df.sort_values(by='utc_time', inplace=True)\n",
    "master_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# ### FIX 3: IMPROVED SIGNIFICANCE NORMALIZATION ###\n",
    "# Use a log-scale followed by min-max scaling to better represent the order-of-magnitude\n",
    "# importance of signal strength, instead of a simple percentile rank.\n",
    "master_df['log_signal'] = np.log10(master_df['signal_strength'] + 1) # Add 1 to avoid log(0)\n",
    "master_df['signal_norm_score'] = master_df.groupby('event_type')['log_signal'].transform(\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min()) if (x.max() - x.min()) > 0 else 0\n",
    ")\n",
    "\n",
    "print(f\"\\nCombined and prepared a total of {len(master_df)} events for analysis.\")\n",
    "\n",
    "\n",
    "# --- STEP 2: DEFINE THE CORE ENGINE LOGIC (WITH CONTEXTUAL FIX) ---\n",
    "\n",
    "EVENT_CONFIG = {\n",
    "    'GW': {'time_window_days': 2.0},\n",
    "    'GRB': {'time_window_days': 0.5},\n",
    "    'DEFAULT': {'time_window_days': 1.0}\n",
    "}\n",
    "WEIGHTS = {'W_st': 0.5, 'W_sig': 0.3, 'W_ctx': 0.2}\n",
    "\n",
    "def calculate_angular_distance(ra1, dec1, ra2, dec2):\n",
    "    c1 = SkyCoord(ra=ra1*u.degree, dec=dec1*u.degree, frame='icrs')\n",
    "    c2 = SkyCoord(ra=ra2*u.degree, dec=dec2*u.degree, frame='icrs')\n",
    "    return c1.separation(c2).degree\n",
    "\n",
    "def calculate_scores(event_A, event_B):\n",
    "    features = {}\n",
    "    features['time_delta_sec'] = abs((event_A['utc_time'] - event_B['utc_time']).total_seconds())\n",
    "    features['angular_dist_deg'] = calculate_angular_distance(event_A['ra_deg'], event_A['dec_deg'], event_B['ra_deg'], event_B['dec_deg'])\n",
    "    features['S_match'] = features['angular_dist_deg'] / (event_A['pos_error_deg'] + event_B['pos_error_deg'] + 1e-6)\n",
    "    \n",
    "    score_spatial = np.exp(-features['S_match'])\n",
    "    score_temporal = np.exp(-features['time_delta_sec'] / 3600)\n",
    "    features['score_spatiotemporal'] = score_spatial * score_temporal\n",
    "\n",
    "    # Use the improved normalized score\n",
    "    features['score_significance'] = event_A['signal_norm_score'] * event_B['signal_norm_score']\n",
    "\n",
    "    # ### FIX 2: ROBUST CONTEXTUAL SCORE ###\n",
    "    # Make the SIMBAD query more robust and improve the check for galaxy types.\n",
    "    try:\n",
    "        # Query a slightly larger region to ensure we find the host\n",
    "        search_radius = max(0.5, event_A['pos_error_deg']) * u.degree\n",
    "        result_table = Simbad.query_region(SkyCoord(ra=event_A['ra_deg']*u.degree, dec=event_A['dec_deg']*u.degree), radius=search_radius)\n",
    "        \n",
    "        # Check for various galaxy classifications, not just 'G'\n",
    "        galaxy_types = ['G', 'Galaxy', 'LINER', 'Seyfert', 'PartofG']\n",
    "        is_galaxy_nearby = any(any(gt in t for gt in galaxy_types) for t in result_table['OTYPE']) if result_table else False\n",
    "        features['score_contextual'] = 1.0 if is_galaxy_nearby else 0.1\n",
    "    except Exception as e:\n",
    "        # print(f\"SIMBAD query failed for {event_A['event_id']}: {e}\") # Uncomment for debugging\n",
    "        features['score_contextual'] = 0.1\n",
    "\n",
    "    features['confidence_score'] = (WEIGHTS['W_st'] * features['score_spatiotemporal'] +\n",
    "                                    WEIGHTS['W_sig'] * features['score_significance'] +\n",
    "                                    WEIGHTS['W_ctx'] * features['score_contextual'])\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "# --- STEP 3: RUN THE ADAPTIVE SEARCH AND SCORE CANDIDATES (Unchanged) ---\n",
    "# The logic here remains the same, but it will now use the corrected functions and data.\n",
    "scored_candidates = []\n",
    "print(\"\\n--- Starting Adaptive Candidate Search with Corrected Logic ---\")\n",
    "# ... (The rest of the script from the previous response remains the same) ...\n",
    "for i in range(len(master_df)):\n",
    "    event_A = master_df.iloc[i]\n",
    "    config = EVENT_CONFIG.get(event_A['event_type'], EVENT_CONFIG['DEFAULT'])\n",
    "    \n",
    "    for j in range(i + 1, len(master_df)):\n",
    "        event_B = master_df.iloc[j]\n",
    "        \n",
    "        time_delta = event_B['utc_time'] - event_A['utc_time']\n",
    "        if time_delta.days > config['time_window_days']:\n",
    "            break\n",
    "            \n",
    "        if calculate_angular_distance(event_A['ra_deg'], event_A['dec_deg'], event_B['ra_deg'], event_B['dec_deg']) < (event_A['pos_error_deg'] + event_B['pos_error_deg']):\n",
    "            scores = calculate_scores(event_A, event_B)\n",
    "            \n",
    "            result = {\n",
    "                'event_A_id': event_A['event_id'], 'event_A_type': event_A['event_type'],\n",
    "                'event_B_id': event_B['event_id'], 'event_B_type': event_B['event_type'],\n",
    "                'confidence_score': scores['confidence_score'], 'score_spatiotemporal': scores['score_spatiotemporal'],\n",
    "                'score_significance': scores['score_significance'], 'score_contextual': scores['score_contextual'],\n",
    "                'time_delta_sec': scores['time_delta_sec'], 'angular_dist_deg': scores['angular_dist_deg'],\n",
    "            }\n",
    "            scored_candidates.append(result)\n",
    "\n",
    "print(f\"Search complete. Found {len(scored_candidates)} candidate pairs.\")\n",
    "\n",
    "# --- STEP 4: FINAL RANKING AND OUTPUT ---\n",
    "if scored_candidates:\n",
    "    final_results_df = pd.DataFrame(scored_candidates)\n",
    "    final_results_df.sort_values(by='confidence_score', ascending=False, inplace=True)\n",
    "    final_results_df.reset_index(drop=True, inplace=True)\n",
    "    print(\"\\n--- Top 10 Correlated Event Candidates (Corrected) ---\")\n",
    "    print(final_results_df.head(10).to_string(formatters={\n",
    "        'confidence_score': '{:,.3f}'.format, 'score_spatiotemporal': '{:,.3f}'.format,\n",
    "        'score_significance': '{:,.3f}'.format, 'score_contextual': '{:,.1f}'.format,\n",
    "        'time_delta_sec': '{:,.1f}'.format, 'angular_dist_deg': '{:,.3f}'.format\n",
    "    }))\n",
    "else:\n",
    "    print(\"\\nNo correlated event candidates found within the specified parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4847c5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined and prepared a total of 298 events for analysis.\n",
      "\n",
      "--- Starting Adaptive Candidate Search ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Events: 100%|| 298/298 [1:20:39<00:00, 16.24s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search complete. Found 13 candidate pairs.\n",
      "\n",
      "--- Top 10 Correlated Event Candidates ---\n",
      "        event_A_id event_A_type       event_B_id event_B_type confidence_score score_spatiotemporal score_significance score_contextual time_delta_sec angular_dist_deg\n",
      "0      bn170817529          GRB         GW170817           GW            0.549                0.990              0.115              0.1           34.9            0.001\n",
      "1         GW190412           GW  GW190413_052954           GW            0.041                0.000              0.068              0.1       86,350.4           20.928\n",
      "2  GW190517_055101           GW  GW190519_153544           GW            0.029                0.000              0.031              0.1      207,882.6           49.552\n",
      "3      bn170804911          GRB      bn170805901          GRB            0.029                0.000              0.029              0.1       85,528.1           14.275\n",
      "4  GW190706_222641           GW  GW190707_093326           GW            0.026                0.000              0.019              0.1       40,004.8           37.954\n",
      "5  GW190803_022701           GW  GW190805_211137           GW            0.026                0.000              0.019              0.1      240,275.4           37.932\n",
      "6  GW190706_222641           GW  GW190708_232457           GW            0.025                0.000              0.017              0.1      176,296.0           35.928\n",
      "7  GW191103_012549           GW  GW191105_143521           GW            0.024                0.000              0.014              0.1      220,172.4           30.145\n",
      "8  GW190929_012149           GW  GW190930_133541           GW            0.024                0.000              0.014              0.1      130,431.7           49.628\n",
      "9         GW190425           GW  GW190426_152155           GW            0.022                0.000              0.008              0.1      111,830.3           33.116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery.simbad import Simbad\n",
    "import astropy.units as u\n",
    "from tqdm import tqdm # Import the tqdm library\n",
    "\n",
    "# --- STEP 1: LOAD AND COMBINE YOUR DATASETS (Corrected for Timezone) ---\n",
    "# (This part remains the same)\n",
    "try:\n",
    "    heasarc_df = pd.read_csv('heasarc_df_year_2017.csv')\n",
    "    gw_df = pd.read_csv('gw_events_complete3.csv')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not find a data file.\")\n",
    "    exit()\n",
    "\n",
    "heasarc_df['utc_time'] = pd.to_datetime(heasarc_df['utc_time']).dt.tz_localize('UTC')\n",
    "gw_df['utc_time'] = pd.to_datetime(gw_df['utc_time']).dt.tz_localize('UTC')\n",
    "\n",
    "master_df = pd.concat([heasarc_df, gw_df], ignore_index=True)\n",
    "master_df.sort_values(by='utc_time', inplace=True)\n",
    "master_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "master_df['log_signal'] = np.log10(master_df['signal_strength'] + 1)\n",
    "master_df['signal_norm_score'] = master_df.groupby('event_type')['log_signal'].transform(\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min()) if (x.max() - x.min()) > 0 else 0\n",
    ")\n",
    "\n",
    "print(f\"Combined and prepared a total of {len(master_df)} events for analysis.\")\n",
    "\n",
    "\n",
    "# --- STEP 2: DEFINE THE CORE ENGINE LOGIC (Unchanged) ---\n",
    "# (The configuration and functions remain the same)\n",
    "EVENT_CONFIG = {\n",
    "    'GW': {'time_window_days': 2.0},\n",
    "    'GRB': {'time_window_days': 0.5},\n",
    "    'DEFAULT': {'time_window_days': 1.0}\n",
    "}\n",
    "WEIGHTS = {'W_st': 0.5, 'W_sig': 0.3, 'W_ctx': 0.2}\n",
    "\n",
    "def calculate_angular_distance(ra1, dec1, ra2, dec2):\n",
    "    c1 = SkyCoord(ra=ra1*u.degree, dec=dec1*u.degree, frame='icrs')\n",
    "    c2 = SkyCoord(ra=ra2*u.degree, dec=dec2*u.degree, frame='icrs')\n",
    "    return c1.separation(c2).degree\n",
    "\n",
    "def calculate_scores(event_A, event_B):\n",
    "    features = {}\n",
    "    features['time_delta_sec'] = abs((event_A['utc_time'] - event_B['utc_time']).total_seconds())\n",
    "    features['angular_dist_deg'] = calculate_angular_distance(event_A['ra_deg'], event_A['dec_deg'], event_B['ra_deg'], event_B['dec_deg'])\n",
    "    features['S_match'] = features['angular_dist_deg'] / (event_A['pos_error_deg'] + event_B['pos_error_deg'] + 1e-6)\n",
    "    \n",
    "    score_spatial = np.exp(-features['S_match'])\n",
    "    score_temporal = np.exp(-features['time_delta_sec'] / 3600)\n",
    "    features['score_spatiotemporal'] = score_spatial * score_temporal\n",
    "\n",
    "    features['score_significance'] = event_A['signal_norm_score'] * event_B['signal_norm_score']\n",
    "\n",
    "    try:\n",
    "        search_radius = max(0.5, event_A['pos_error_deg']) * u.degree\n",
    "        result_table = Simbad.query_region(SkyCoord(ra=event_A['ra_deg']*u.degree, dec=event_A['dec_deg']*u.degree), radius=search_radius)\n",
    "        galaxy_types = ['G', 'Galaxy', 'LINER', 'Seyfert', 'PartofG']\n",
    "        is_galaxy_nearby = any(any(gt in t for gt in galaxy_types) for t in result_table['OTYPE']) if result_table else False\n",
    "        features['score_contextual'] = 1.0 if is_galaxy_nearby else 0.1\n",
    "    except Exception as e:\n",
    "        features['score_contextual'] = 0.1\n",
    "\n",
    "    features['confidence_score'] = (WEIGHTS['W_st'] * features['score_spatiotemporal'] +\n",
    "                                    WEIGHTS['W_sig'] * features['score_significance'] +\n",
    "                                    WEIGHTS['W_ctx'] * features['score_contextual'])\n",
    "    return features\n",
    "\n",
    "\n",
    "# --- STEP 3: RUN THE ADAPTIVE SEARCH WITH PROGRESS BAR ---\n",
    "\n",
    "scored_candidates = []\n",
    "print(\"\\n--- Starting Adaptive Candidate Search ---\")\n",
    "\n",
    "# ### PROGRESS BAR INTEGRATION ###\n",
    "# Wrap the main loop's iterator with tqdm() to create the progress bar.\n",
    "for i in tqdm(range(len(master_df)), desc=\"Processing Events\"):\n",
    "    event_A = master_df.iloc[i]\n",
    "    config = EVENT_CONFIG.get(event_A['event_type'], EVENT_CONFIG['DEFAULT'])\n",
    "    \n",
    "    for j in range(i + 1, len(master_df)):\n",
    "        event_B = master_df.iloc[j]\n",
    "        \n",
    "        time_delta = event_B['utc_time'] - event_A['utc_time']\n",
    "        if time_delta.days > config['time_window_days']:\n",
    "            break\n",
    "            \n",
    "        if calculate_angular_distance(event_A['ra_deg'], event_A['dec_deg'], event_B['ra_deg'], event_B['dec_deg']) < (event_A['pos_error_deg'] + event_B['pos_error_deg']):\n",
    "            scores = calculate_scores(event_A, event_B)\n",
    "            \n",
    "            result = {\n",
    "                'event_A_id': event_A['event_id'], 'event_A_type': event_A['event_type'],\n",
    "                'event_B_id': event_B['event_id'], 'event_B_type': event_B['event_type'],\n",
    "                'confidence_score': scores['confidence_score'], 'score_spatiotemporal': scores['score_spatiotemporal'],\n",
    "                'score_significance': scores['score_significance'], 'score_contextual': scores['score_contextual'],\n",
    "                'time_delta_sec': scores['time_delta_sec'], 'angular_dist_deg': scores['angular_dist_deg'],\n",
    "            }\n",
    "            scored_candidates.append(result)\n",
    "\n",
    "print(f\"\\nSearch complete. Found {len(scored_candidates)} candidate pairs.\")\n",
    "\n",
    "\n",
    "# --- STEP 4: FINAL RANKING AND OUTPUT (Unchanged) ---\n",
    "# (This part remains the same)\n",
    "if scored_candidates:\n",
    "    final_results_df = pd.DataFrame(scored_candidates)\n",
    "    final_results_df.sort_values(by='confidence_score', ascending=False, inplace=True)\n",
    "    final_results_df.reset_index(drop=True, inplace=True)\n",
    "    print(\"\\n--- Top 10 Correlated Event Candidates ---\")\n",
    "    print(final_results_df.head(10).to_string(formatters={\n",
    "        'confidence_score': '{:,.3f}'.format, 'score_spatiotemporal': '{:,.3f}'.format,\n",
    "        'score_significance': '{:,.3f}'.format, 'score_contextual': '{:,.1f}'.format,\n",
    "        'time_delta_sec': '{:,.1f}'.format, 'angular_dist_deg': '{:,.3f}'.format\n",
    "    }))\n",
    "else:\n",
    "    print(\"\\nNo correlated event candidates found within the specified parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63314604",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_df.to_csv('final_results_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (try_it_out venv)",
   "language": "python",
   "name": "implementation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
